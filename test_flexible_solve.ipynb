{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Leukemia Cell Lines in Protein Atlas: ['Kasumi-6', 'MOLM-6', 'KO52', 'MUTZ-3', 'GDM-1', 'Kasumi-1', 'Mono-Mac-1', 'OCI-AML-5', 'KG-1', 'OCI-AML-2', 'SKM-1', 'SIG-M5', 'NOMO-1', 'P31/FUJ', 'AML-193', 'Mono-Mac-6', 'UKE-1', 'EoL-1', 'CMK', 'Loucy', 'U-937', 'ME-1', 'THP-1', 'MOLT-13', 'NALM-1', 'HNT-34', 'NB4', 'HL-60', 'MOLT-16', 'PLB-985', 'MHH-CALL-2', 'EM-2', 'MOLM-13', 'SET-2', 'MHH-CALL-4', 'MV4-11', 'SEM', 'PL-21', 'SKNO-1', 'HEL', 'LAMA-84', 'M-07e', 'MHH-CALL-3', 'KCL-22', 'TF-1', 'Kasumi-2', 'Ku812', 'KE-37', 'CML-T1', 'ML-2', 'MOLM-16', 'NCO2', 'SUP-B15', 'HEL', 'JK-1', 'P12-Ichikawa', 'NALM-19', 'PF-382', 'RPMI-8402', 'MOLT-3', 'OCI-AML-3', 'MUTZ-5', 'HMC-1', 'F-36P', 'TALL-1', 'CCRF-SB', 'RCH-ACV', 'Peer', 'JURKAT', 'JURL-MK1', 'Jurkat', 'KOPN-8', 'JVM-3', 'NALM-6', 'REH', 'ALL-SIL', 'MEC-1', 'DND-41', 'BDCM', 'BV-173', 'OCI-M1', 'MEG-01', 'MOLT-4', 'SUP-T11', 'HPB-ALL', 'SUP-T1', 'JM-1', '697', 'OCI-M2', 'RS4;11', 'K-562', 'KYO-1', 'HAP1']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "samples_df = pd.read_csv('/Users/Surya/Downloads/screen-tsv-download.tsv', header=None, delimiter='\\t')\n",
    "samples = samples_df\n",
    "# URL of the Protein Atlas Leukemia page\n",
    "url = \"https://www.proteinatlas.org/humanproteome/cell+line/leukemia\"\n",
    "\n",
    "# Send a GET request to the webpage\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the webpage content\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Locate the script tag containing the desired identifier\n",
    "    script_tags = soup.find_all('script')\n",
    "    for script in script_tags:\n",
    "        # Look for the specific identifier in the script content\n",
    "        if \"var plot = $('#celline_prio_leukemia_LAML')\" in script.text:\n",
    "            # Extract the full line containing the scatterPlot data\n",
    "            full_line = re.search(r\"var plot = \\$\\('#celline_prio_leukemia_LAML'\\)\\.scatterPlot\\((.*?)\\);\", script.text, re.DOTALL)\n",
    "            # if full_line:\n",
    "            full_line_text = full_line.group(1)  # Extract the full JSON-like data\n",
    "            cell_lines = re.findall(r'\"name\":\"(.*?)\"', full_line_text)\n",
    "            #Strip trailers\n",
    "            cell_lines = [x.split(' ')[0].replace('\\\\','') for x in cell_lines]\n",
    "            print('All Leukemia Cell Lines in Protein Atlas:',cell_lines)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kasumi-6',\n",
       " 'MOLM-6',\n",
       " 'KO52',\n",
       " 'MUTZ-3',\n",
       " 'GDM-1',\n",
       " 'Kasumi-1',\n",
       " 'Mono-Mac-1',\n",
       " 'OCI-AML-5',\n",
       " 'KG-1',\n",
       " 'OCI-AML-2',\n",
       " 'SKM-1',\n",
       " 'SIG-M5',\n",
       " 'NOMO-1',\n",
       " 'P31/FUJ',\n",
       " 'AML-193',\n",
       " 'Mono-Mac-6',\n",
       " 'UKE-1',\n",
       " 'EoL-1',\n",
       " 'CMK',\n",
       " 'Loucy',\n",
       " 'U-937',\n",
       " 'ME-1',\n",
       " 'THP-1',\n",
       " 'MOLT-13',\n",
       " 'NALM-1',\n",
       " 'HNT-34',\n",
       " 'NB4',\n",
       " 'HL-60',\n",
       " 'MOLT-16',\n",
       " 'PLB-985',\n",
       " 'MHH-CALL-2',\n",
       " 'EM-2',\n",
       " 'MOLM-13',\n",
       " 'SET-2',\n",
       " 'MHH-CALL-4',\n",
       " 'MV4-11',\n",
       " 'SEM',\n",
       " 'PL-21',\n",
       " 'SKNO-1',\n",
       " 'HEL',\n",
       " 'LAMA-84',\n",
       " 'M-07e',\n",
       " 'MHH-CALL-3',\n",
       " 'KCL-22',\n",
       " 'TF-1',\n",
       " 'Kasumi-2',\n",
       " 'Ku812',\n",
       " 'KE-37',\n",
       " 'CML-T1',\n",
       " 'ML-2',\n",
       " 'MOLM-16',\n",
       " 'NCO2',\n",
       " 'SUP-B15',\n",
       " 'HEL',\n",
       " 'JK-1',\n",
       " 'P12-Ichikawa',\n",
       " 'NALM-19',\n",
       " 'PF-382',\n",
       " 'RPMI-8402',\n",
       " 'MOLT-3',\n",
       " 'OCI-AML-3',\n",
       " 'MUTZ-5',\n",
       " 'HMC-1',\n",
       " 'F-36P',\n",
       " 'TALL-1',\n",
       " 'CCRF-SB',\n",
       " 'RCH-ACV',\n",
       " 'Peer',\n",
       " 'JURKAT',\n",
       " 'JURL-MK1',\n",
       " 'Jurkat',\n",
       " 'KOPN-8',\n",
       " 'JVM-3',\n",
       " 'NALM-6',\n",
       " 'REH',\n",
       " 'ALL-SIL',\n",
       " 'MEC-1',\n",
       " 'DND-41',\n",
       " 'BDCM',\n",
       " 'BV-173',\n",
       " 'OCI-M1',\n",
       " 'MEG-01',\n",
       " 'MOLT-4',\n",
       " 'SUP-T11',\n",
       " 'HPB-ALL',\n",
       " 'SUP-T1',\n",
       " 'JM-1',\n",
       " '697',\n",
       " 'OCI-M2',\n",
       " 'RS4;11',\n",
       " 'K-562',\n",
       " 'KYO-1',\n",
       " 'HAP1']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_lines = cell_lines[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_lines.append('Jurkat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kasumi-6', 'MOLM-6', 'KO52', 'MUTZ-3', 'GDM-1', 'Jurkat']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kasumi-6', 'kasumi-6', 'kasumi6']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'cell_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/web_scraper/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:175\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index_class_helper.pxi:70\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cell_type'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 80\u001b[0m\n\u001b[1;32m     78\u001b[0m cell_lines_curr \u001b[38;5;241m=\u001b[39m cell_lines\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# Find matching rows\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m matched_df \u001b[38;5;241m=\u001b[39m \u001b[43mfind_matching_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell_lines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Display the output DataFrame\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(matched_df)\n",
      "Cell \u001b[0;32mIn[47], line 66\u001b[0m, in \u001b[0;36mfind_matching_rows\u001b[0;34m(cell_lines, samples_df)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Match rows where cell_type contains any of the query strings (case-insensitively)\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m samples_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mquery_string\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcell_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mquery_string\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mquery_strings\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     67\u001b[0m         matched_row \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[1;32m     68\u001b[0m         matched_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatched_identifier\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m identifier\n",
      "Cell \u001b[0;32mIn[47], line 66\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Match rows where cell_type contains any of the query strings (case-insensitively)\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m samples_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(query_string \u001b[38;5;129;01min\u001b[39;00m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcell_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m query_string \u001b[38;5;129;01min\u001b[39;00m query_strings):\n\u001b[1;32m     67\u001b[0m         matched_row \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[1;32m     68\u001b[0m         matched_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatched_identifier\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m identifier\n",
      "File \u001b[0;32m~/.conda/envs/web_scraper/lib/python3.9/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/.conda/envs/web_scraper/lib/python3.9/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/.conda/envs/web_scraper/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cell_type'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "def extract_name_list_synonyms(data, query):\n",
    "    \"\"\"\n",
    "    Extract the name list and synonyms for a specific query from the API response.\n",
    "\n",
    "    Args:\n",
    "        data (dict): Parsed JSON response from the Cellosaurus API.\n",
    "        query (str): The cell line query string.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the identifier and its corresponding synonyms.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    # Iterate over each cell line in the 'cell-line-list'\n",
    "    for cell_line_entry in data.get('cell-line-list', []):\n",
    "        # Find the identifier\n",
    "        identifier = None\n",
    "        synonyms = []\n",
    "        for name_entry in cell_line_entry.get('name-list', []):\n",
    "            if name_entry['type'] == 'identifier':\n",
    "                identifier = name_entry['value']\n",
    "            elif name_entry['type'] == 'synonym':\n",
    "                synonyms.append(name_entry['value'])\n",
    "\n",
    "        # Store the identifier and its synonyms if it matches the query\n",
    "        if identifier.lower() == query.lower():\n",
    "            results[identifier] = synonyms\n",
    "\n",
    "    return results\n",
    "\n",
    "def find_matching_rows(cell_lines, samples_df):\n",
    "    \"\"\"\n",
    "    Matches rows in the samples DataFrame based on cell line names and synonyms, case-insensitively.\n",
    "\n",
    "    Args:\n",
    "        cell_lines (list): List of cell lines to query.\n",
    "        samples_df (pd.DataFrame): DataFrame containing \"cell_type\" and \"tissue\" columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with matched rows and an additional column for the identifier.\n",
    "    \"\"\"\n",
    "    matched_rows = []\n",
    "\n",
    "    # Normalize cell_lines to lowercase for case-insensitive matching\n",
    "    normalized_cell_lines = [line.lower() for line in cell_lines]\n",
    "\n",
    "    for query in normalized_cell_lines:\n",
    "        url = f\"https://api.cellosaurus.org/search/cell-line?q={query}\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            # Parse JSON response\n",
    "            api_data = response.json()\n",
    "            # Extract synonyms\n",
    "            synonyms_data = extract_name_list_synonyms(api_data.get('Cellosaurus', {}), query)\n",
    "\n",
    "            for identifier, synonyms in synonyms_data.items():\n",
    "                # Combine identifier and synonyms into one list of query strings\n",
    "                query_strings = [identifier.lower()] + [synonym.lower() for synonym in synonyms]\n",
    "                print(query_strings)\n",
    "\n",
    "                # Match rows where cell_type contains any of the query strings (case-insensitively)\n",
    "                for _, row in samples_df.iterrows():\n",
    "                    if any(query_string in row['cell_type'].lower() for query_string in query_strings):\n",
    "                        matched_row = row.to_dict()\n",
    "                        matched_row['matched_identifier'] = identifier\n",
    "                        matched_rows.append(matched_row)\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for {query}. HTTP Status Code: {response.status_code}\")\n",
    "\n",
    "    # Create a new DataFrame from the matched rows\n",
    "    return pd.DataFrame(matched_rows)\n",
    "\n",
    "# Example cell lines list\n",
    "samples_df = pd.read_csv('/Users/Surya/Downloads/screen-tsv-download.tsv', header=None, delimiter='\\t')\n",
    "cell_lines_curr = cell_lines\n",
    "# Find matching rows\n",
    "matched_df = find_matching_rows(cell_lines, samples_df)\n",
    "\n",
    "# Display the output DataFrame\n",
    "print(matched_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22Rv1</td>\n",
       "      <td>prostate gland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22Rv1 treated with 10 nM 17?-hydroxy-5?-andros...</td>\n",
       "      <td>prostate gland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8988T</td>\n",
       "      <td>pancreas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A172</td>\n",
       "      <td>brain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A549</td>\n",
       "      <td>lung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>WERI-Rb-1</td>\n",
       "      <td>eye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>WI38</td>\n",
       "      <td>lung</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>WI38 genetically modified using stable transfe...</td>\n",
       "      <td>connective tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>WI38 genetically modified using stable transfe...</td>\n",
       "      <td>connective tissue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>WI38 genetically modified using stable transfe...</td>\n",
       "      <td>lung</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1518 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      0                  1\n",
       "0                                                 22Rv1     prostate gland\n",
       "1     22Rv1 treated with 10 nM 17?-hydroxy-5?-andros...     prostate gland\n",
       "2                                                 8988T           pancreas\n",
       "3                                                  A172              brain\n",
       "4                                                  A549               lung\n",
       "...                                                 ...                ...\n",
       "1513                                          WERI-Rb-1                eye\n",
       "1514                                               WI38               lung\n",
       "1515  WI38 genetically modified using stable transfe...  connective tissue\n",
       "1516  WI38 genetically modified using stable transfe...  connective tissue\n",
       "1517  WI38 genetically modified using stable transfe...               lung\n",
       "\n",
       "[1518 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cell_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.conda/envs/web_scraper/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:175\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index_class_helper.pxi:70\u001b[0m, in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cell_type'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 93\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(matched_rows)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Example cell lines list\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# cell_lines = [\"KO52\", \"Kasumi-6\", \"MOTM-13\", \"Jurkat\"]\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     91\u001b[0m \n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Find matching rows\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m matched_df \u001b[38;5;241m=\u001b[39m \u001b[43mfind_matching_rows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcell_lines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msamples_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Display the output DataFrame\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(matched_df)\n",
      "Cell \u001b[0;32mIn[15], line 75\u001b[0m, in \u001b[0;36mfind_matching_rows\u001b[0;34m(cell_lines, samples_df)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Match rows where cell_type contains any of the query strings (case-insensitively)\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m samples_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mquery_string\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcell_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mquery_string\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mquery_strings\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     76\u001b[0m         matched_row \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[1;32m     77\u001b[0m         matched_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatched_identifier\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m identifier\n",
      "Cell \u001b[0;32mIn[15], line 75\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Match rows where cell_type contains any of the query strings (case-insensitively)\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m samples_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(query_string \u001b[38;5;129;01min\u001b[39;00m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcell_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m query_string \u001b[38;5;129;01min\u001b[39;00m query_strings):\n\u001b[1;32m     76\u001b[0m         matched_row \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[1;32m     77\u001b[0m         matched_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatched_identifier\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m identifier\n",
      "File \u001b[0;32m~/.conda/envs/web_scraper/lib/python3.9/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/.conda/envs/web_scraper/lib/python3.9/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/.conda/envs/web_scraper/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cell_type'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "def extract_name_list_synonyms(data, query):\n",
    "    \"\"\"\n",
    "    Extract the name list and synonyms for a specific query from the API response.\n",
    "\n",
    "    Args:\n",
    "        data (dict): Parsed JSON response from the Cellosaurus API.\n",
    "        query (str): The cell line query string.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the identifier, synonyms, and disease information.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for cell_line_entry in data.get('cell-line-list', []):\n",
    "        # Find the identifier\n",
    "        identifier = None\n",
    "        synonyms = []\n",
    "        disease_label = None\n",
    "\n",
    "        for name_entry in cell_line_entry.get('name-list', []):\n",
    "            if name_entry['type'] == 'identifier':\n",
    "                identifier = name_entry['value']\n",
    "            elif name_entry['type'] == 'synonym':\n",
    "                synonyms.append(name_entry['value'])\n",
    "\n",
    "        # Retrieve the first disease-list label\n",
    "        disease_list = cell_line_entry.get('disease-list', [])\n",
    "        if disease_list and 'label' in disease_list[0]:\n",
    "            disease_label = disease_list[0]['label']\n",
    "\n",
    "        # Store the identifier, synonyms, and disease label if it matches the query\n",
    "        if identifier and identifier.lower() == query.lower():\n",
    "            results[identifier] = {\n",
    "                'synonyms': synonyms,\n",
    "                'disease': disease_label\n",
    "            }\n",
    "\n",
    "    return results\n",
    "\n",
    "def find_matching_rows(cell_lines, samples_df):\n",
    "    \"\"\"\n",
    "    Matches rows in the samples DataFrame based on cell line names and synonyms,\n",
    "    and retrieves disease information from the Cellosaurus API.\n",
    "\n",
    "    Args:\n",
    "        cell_lines (list): List of cell lines to query.\n",
    "        samples_df (pd.DataFrame): DataFrame containing \"cell_type\" and \"tissue\" columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with matched rows and additional columns for the identifier and disease label.\n",
    "    \"\"\"\n",
    "    matched_rows = []\n",
    "\n",
    "    # Normalize cell_lines to lowercase for case-insensitive matching\n",
    "    normalized_cell_lines = [line.lower() for line in cell_lines]\n",
    "\n",
    "    for query in normalized_cell_lines:\n",
    "        url = f\"https://api.cellosaurus.org/search/cell-line?q={query}\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            # Parse JSON response\n",
    "            api_data = response.json()\n",
    "            # Extract synonyms and disease info\n",
    "            synonyms_data = extract_name_list_synonyms(api_data.get('Cellosaurus', {}), query)\n",
    "\n",
    "            for identifier, data in synonyms_data.items():\n",
    "                query_strings = [identifier.lower()] + [synonym.lower() for synonym in data['synonyms']]\n",
    "                disease_label = data['disease']\n",
    "\n",
    "                # Match rows where cell_type contains any of the query strings (case-insensitively)\n",
    "                for _, row in samples_df.iterrows():\n",
    "                    if any(query_string in row['cell_type'].lower() for query_string in query_strings):\n",
    "                        matched_row = row.to_dict()\n",
    "                        matched_row['matched_identifier'] = identifier\n",
    "                        matched_row['disease_label'] = disease_label\n",
    "                        matched_rows.append(matched_row)\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for {query}. HTTP Status Code: {response.status_code}\")\n",
    "\n",
    "    # Create a new DataFrame from the matched rows\n",
    "    return pd.DataFrame(matched_rows)\n",
    "\n",
    "# Example cell lines list\n",
    "# cell_lines = [\"KO52\", \"Kasumi-6\", \"MOTM-13\", \"Jurkat\"]\n",
    "\n",
    "# Example samples DataFrame\n",
    "\n",
    "\n",
    "# Find matching rows\n",
    "matched_df = find_matching_rows(cell_lines, samples_df)\n",
    "\n",
    "# Display the output DataFrame\n",
    "print(matched_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cell_lines' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcell_lines\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cell_lines' is not defined"
     ]
    }
   ],
   "source": [
    "cell_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              cell_type            tissue matched_identifier disease_label\n",
      "0    ko52-derived cells       Bone marrow               KO52          None\n",
      "1  kasumi-6 tumor cells        Lymph node           Kasumi-6          None\n",
      "2          jurkat cells  Peripheral blood             Jurkat          None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "def extract_name_list_synonyms(data, query):\n",
    "    \"\"\"\n",
    "    Extract the name list and synonyms for a specific query from the API response.\n",
    "\n",
    "    Args:\n",
    "        data (dict): Parsed JSON response from the Cellosaurus API.\n",
    "        query (str): The cell line query string.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the identifier and its corresponding synonyms.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for cell_line_entry in data.get('cell-line-list', []):\n",
    "        # Find the identifier\n",
    "        identifier = None\n",
    "        synonyms = []\n",
    "\n",
    "        for name_entry in cell_line_entry.get('name-list', []):\n",
    "            if name_entry['type'] == 'identifier':\n",
    "                identifier = name_entry['value']\n",
    "            elif name_entry['type'] == 'synonym':\n",
    "                synonyms.append(name_entry['value'])\n",
    "\n",
    "        # Store the identifier and its synonyms if it matches the query\n",
    "        if identifier and identifier.lower() == query.lower():\n",
    "            results[identifier] = synonyms\n",
    "\n",
    "    return results\n",
    "\n",
    "def fetch_disease_label(identifier):\n",
    "    \"\"\"\n",
    "    Fetch the disease label for a given identifier from the Cellosaurus API.\n",
    "\n",
    "    Args:\n",
    "        identifier (str): The matched identifier for which to fetch disease information.\n",
    "\n",
    "    Returns:\n",
    "        str: The first disease label from the disease-list, or None if not found.\n",
    "    \"\"\"\n",
    "    url = f\"https://api.cellosaurus.org/search/cell-line?q={identifier}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        for cell_line_entry in data.get('cell-line-list', []):\n",
    "            if cell_line_entry.get('name-list', [{}])[0].get('value', '').lower() == identifier.lower():\n",
    "                disease_list = cell_line_entry.get('disease-list', [])\n",
    "                if disease_list and 'label' in disease_list[0]:\n",
    "                    return disease_list[0]['label']\n",
    "    return None\n",
    "\n",
    "def find_matching_rows(cell_lines, samples_df):\n",
    "    \"\"\"\n",
    "    Matches rows in the samples DataFrame based on cell line names and synonyms,\n",
    "    and retrieves disease information only for matched identifiers.\n",
    "\n",
    "    Args:\n",
    "        cell_lines (list): List of cell lines to query.\n",
    "        samples_df (pd.DataFrame): DataFrame containing \"cell_type\" and \"tissue\" columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with matched rows and additional columns for the identifier and disease label.\n",
    "    \"\"\"\n",
    "    matched_rows = []\n",
    "\n",
    "    # Normalize cell_lines to lowercase for case-insensitive matching\n",
    "    normalized_cell_lines = [line.lower() for line in cell_lines]\n",
    "\n",
    "    for query in normalized_cell_lines:\n",
    "        url = f\"https://api.cellosaurus.org/search/cell-line?q={query}\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            # Parse JSON response\n",
    "            api_data = response.json()\n",
    "            # Extract synonyms\n",
    "            synonyms_data = extract_name_list_synonyms(api_data.get('Cellosaurus', {}), query)\n",
    "\n",
    "            for identifier, synonyms in synonyms_data.items():\n",
    "                query_strings = [identifier.lower()] + [synonym.lower() for synonym in synonyms]\n",
    "\n",
    "                # Match rows where cell_type contains any of the query strings (case-insensitively)\n",
    "                for _, row in samples_df.iterrows():\n",
    "                    if any(query_string in row['cell_type'].lower() for query_string in query_strings):\n",
    "                        # Fetch disease label only after finding a match\n",
    "                        disease_label = fetch_disease_label(identifier)\n",
    "\n",
    "                        matched_row = row.to_dict()\n",
    "                        matched_row['matched_identifier'] = identifier\n",
    "                        matched_row['disease_label'] = disease_label\n",
    "                        matched_rows.append(matched_row)\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for {query}. HTTP Status Code: {response.status_code}\")\n",
    "\n",
    "    # Create a new DataFrame from the matched rows\n",
    "    return pd.DataFrame(matched_rows)\n",
    "\n",
    "# Example cell lines list\n",
    "cell_lines = [\"KO52\", \"Kasumi-6\", \"MOTM-13\", \"Jurkat\"]\n",
    "\n",
    "# Example samples DataFrame\n",
    "data = {\n",
    "    \"cell_type\": [\"ko52-derived cells\", \"kasumi-6 tumor cells\", \"some unrelated cells\", \"jurkat cells\"],\n",
    "    \"tissue\": [\"Bone marrow\", \"Lymph node\", \"Liver\", \"Peripheral blood\"]\n",
    "}\n",
    "samples_df = pd.DataFrame(data)\n",
    "\n",
    "# Find matching rows\n",
    "matched_df = find_matching_rows(cell_lines, samples_df)\n",
    "\n",
    "# Display the output DataFrame\n",
    "print(matched_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web_scraper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
